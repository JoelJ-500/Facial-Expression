{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCaDX_h0QvBE"
      },
      "source": [
        "# **Three Pre-Trained Models Used**\n",
        "\n",
        "\n",
        "1.   VGG16\n",
        "2.   ResNet50\n",
        "3.   InceptionV3\n",
        "\n",
        "\n",
        "This notebook creates, trains and evaluates an ensemble model using three pre-trained models, that reads facial expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UceAtbJzYWX7"
      },
      "source": [
        "# **Upload and extract CK+ dataset into Collab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "p1Lb_wJFORV4",
        "outputId": "dcee86a3-3d8c-4771-d02b-ed136ecfddff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3b860905-63d2-45ff-b7bd-99b2540fdd8b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3b860905-63d2-45ff-b7bd-99b2540fdd8b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving CK+spl.zip to CK+spl.zip\n"
          ]
        }
      ],
      "source": [
        "# Get zip from PC\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEY6wYE1vqHq",
        "outputId": "5817d381-d211-4a1d-d05f-e87a3a7bafd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted:\n",
            "['.config', 'CK+spl.zip', 'Training', 'Validation', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "# Extract ZIP file\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the uploaded ZIP file\n",
        "zip_file_path = '/content/CK+spl.zip'\n",
        "extract_folder = '/content/'      # Destination folder\n",
        "\n",
        "# Create a directory to extract files\n",
        "os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "# Extract ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "# Verify extraction\n",
        "print(\"Files extracted:\")\n",
        "print(os.listdir(extract_folder))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGos371AY4GY"
      },
      "source": [
        "# **Load Pre-trained models**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6ecqmU2ZTKY",
        "outputId": "d9735ebe-d910-4025-c491-4b4116ae2cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load Pre-trained Models\n",
        "base_model1 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model2 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model3 = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MMqTdBpbAIl"
      },
      "source": [
        "# **Freeze the Base Layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haj_37f3wHyy"
      },
      "outputs": [],
      "source": [
        "for layer in base_model1.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in base_model2.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in base_model3.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYiFfhYbwW3K"
      },
      "source": [
        "# **Modify the models by adding new layers for facial expression recognition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg42jhtawcef"
      },
      "outputs": [],
      "source": [
        "def add_new_layers(base_model):\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    # Assuming 7 classes for facial expressions (e.g., happy, sad, angry, etc.)\n",
        "    predictions = Dense(7, activation='softmax')(x)\n",
        "    return Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Create modified models for facial expression recognition\n",
        "model1 = add_new_layers(base_model1)\n",
        "model2 = add_new_layers(base_model2)\n",
        "model3 = add_new_layers(base_model3)\n",
        "\n",
        "# Compile the Modified Models\n",
        "model1.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wKA1ojjxSUl"
      },
      "source": [
        "# **Preprocess CK+ data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozDBELLS6grK",
        "outputId": "63201064-cf7e-4763-b8e5-fef6fa0e3a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 784 images belonging to 7 classes.\n",
            "Found 197 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Path to the dataset\n",
        "train_dir = '/content/Training'\n",
        "val_dir = '/content/Validation'\n",
        "\n",
        "# Image data generators for training and validation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generators for training and validation\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QayYF5ro9TJB"
      },
      "source": [
        "# **Train the models! :D**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2LI-upbT9X7Q",
        "outputId": "67308416-9c03-4e56-e5cd-610d1b0b8590"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 25s/step - accuracy: 0.0731 - loss: 2.2808 - val_accuracy: 0.0761 - val_loss: 2.2446\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 25s/step - accuracy: 0.0607 - loss: 2.2208 - val_accuracy: 0.0761 - val_loss: 2.2024\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 25s/step - accuracy: 0.0893 - loss: 2.1649 - val_accuracy: 0.0761 - val_loss: 2.1632\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 26s/step - accuracy: 0.0637 - loss: 2.1442 - val_accuracy: 0.0761 - val_loss: 2.1270\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 25s/step - accuracy: 0.0815 - loss: 2.0961 - val_accuracy: 0.0761 - val_loss: 2.0948\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 24s/step - accuracy: 0.0904 - loss: 2.0386 - val_accuracy: 0.0761 - val_loss: 2.0656\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 25s/step - accuracy: 0.0859 - loss: 2.0317 - val_accuracy: 0.0761 - val_loss: 2.0398\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 24s/step - accuracy: 0.0741 - loss: 2.0032 - val_accuracy: 0.0761 - val_loss: 2.0159\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m645s\u001b[0m 25s/step - accuracy: 0.0825 - loss: 1.9796 - val_accuracy: 0.0761 - val_loss: 1.9949\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 24s/step - accuracy: 0.1030 - loss: 1.9632 - val_accuracy: 0.0761 - val_loss: 1.9753\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 8s/step - accuracy: 0.1718 - loss: 2.2305 - val_accuracy: 0.1777 - val_loss: 2.1122\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 7s/step - accuracy: 0.1835 - loss: 2.0989 - val_accuracy: 0.2538 - val_loss: 1.9963\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 8s/step - accuracy: 0.2489 - loss: 1.9751 - val_accuracy: 0.2538 - val_loss: 1.9161\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 8s/step - accuracy: 0.2514 - loss: 1.8948 - val_accuracy: 0.2538 - val_loss: 1.8671\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 8s/step - accuracy: 0.2735 - loss: 1.8403 - val_accuracy: 0.2538 - val_loss: 1.8407\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 7s/step - accuracy: 0.2787 - loss: 1.8074 - val_accuracy: 0.2538 - val_loss: 1.8285\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 8s/step - accuracy: 0.2471 - loss: 1.8232 - val_accuracy: 0.2538 - val_loss: 1.8227\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 7s/step - accuracy: 0.2337 - loss: 1.8388 - val_accuracy: 0.2538 - val_loss: 1.8209\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 7s/step - accuracy: 0.2789 - loss: 1.7925 - val_accuracy: 0.2690 - val_loss: 1.8194\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 7s/step - accuracy: 0.2261 - loss: 1.8209 - val_accuracy: 0.2690 - val_loss: 1.8183\n",
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 6s/step - accuracy: 0.1477 - loss: 2.0837 - val_accuracy: 0.2183 - val_loss: 1.9689\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 5s/step - accuracy: 0.2414 - loss: 1.9517 - val_accuracy: 0.2183 - val_loss: 1.9130\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 6s/step - accuracy: 0.2573 - loss: 1.8757 - val_accuracy: 0.2284 - val_loss: 1.8734\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 5s/step - accuracy: 0.3052 - loss: 1.8221 - val_accuracy: 0.2487 - val_loss: 1.8385\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5s/step - accuracy: 0.2948 - loss: 1.8424 - val_accuracy: 0.2690 - val_loss: 1.8047\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 5s/step - accuracy: 0.3142 - loss: 1.8105 - val_accuracy: 0.3046 - val_loss: 1.7737\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 5s/step - accuracy: 0.3199 - loss: 1.7660 - val_accuracy: 0.3198 - val_loss: 1.7460\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 5s/step - accuracy: 0.3739 - loss: 1.7431 - val_accuracy: 0.3553 - val_loss: 1.7216\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 5s/step - accuracy: 0.3695 - loss: 1.7428 - val_accuracy: 0.3706 - val_loss: 1.6984\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 5s/step - accuracy: 0.3729 - loss: 1.7228 - val_accuracy: 0.3756 - val_loss: 1.6772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a93f1af7-54e9-4e1d-8654-45f56684305e\", \"model1.h5\", 60551384)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_067a60bd-a78a-47be-97bc-87149c732d2c\", \"model2.h5\", 101257872)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ac978700-d172-4873-915c-08b95eb4f149\", \"model3.h5\", 94514880)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "history1 = model1.fit(train_generator, validation_data=val_generator, epochs=10, batch_size=32)\n",
        "history2 = model2.fit(train_generator, validation_data=val_generator, epochs=10, batch_size=32)\n",
        "history3 = model3.fit(train_generator, validation_data=val_generator, epochs=10, batch_size=32)\n",
        "\n",
        "\n",
        "model1.save('model1.h5')\n",
        "model2.save('model2.h5')\n",
        "model3.save('model3.h5')\n",
        "\n",
        "files.download('model1.h5')\n",
        "files.download('model2.h5')\n",
        "files.download('model3.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the models**\n",
        "Collab auto deletes the work env, so we must save the models locally and then import it again, before making the ensemble predictions."
      ],
      "metadata": {
        "id": "K2oTO6eBX-gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model from PC\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "uQ6i1fq7YSFj",
        "outputId": "905e0186-92b2-4733-dbed-df25eafbb056"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-523394bd-0275-4f3b-b67f-9788327b2670\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-523394bd-0275-4f3b-b67f-9788327b2670\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model1.h5 to model1.h5\n",
            "Saving model2.h5 to model2.h5\n",
            "Saving model3.h5 to model3.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load models\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model1 = load_model('/content/model1.h5')\n",
        "model2 = load_model('/content/model2.h5')\n",
        "model3 = load_model('/content/model3.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QARJXJfYcJxh",
        "outputId": "42728227-4871-4809-c467-dc1aed08d7aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset so it is similar to how it was before training\n",
        "# Path to the dataset\n",
        "test_dir = '/content/Training/'\n",
        "\n",
        "# Image data generator for test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generator for test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn0p6SPGgj44",
        "outputId": "eee1291a-b14e-41bc-b3ef-622c1f8bea72"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 784 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create ensemble predictions**"
      ],
      "metadata": {
        "id": "vt2WuomOhRC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions1 = model1.predict(test_generator)\n",
        "predictions2 = model2.predict(test_generator)\n",
        "predictions3 = model3.predict(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5wB3TxqhXmN",
        "outputId": "0a7dc811-d84a-4c87-b4e2-a832b0d4dd32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 3/25\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:22\u001b[0m 20s/step"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Average the predictions to create an ensemble\n",
        "ensemble_predictions = (predictions1 + predictions2 + predictions3) / 3\n",
        "print(ensemble_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXSSEwizj4yH",
        "outputId": "f369b18d-172b-495e-d6be-0799da7ce6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.16935939 0.08973428 0.1668361  ... 0.15232112 0.11053298 0.1883529 ]\n",
            " [0.18469612 0.08727866 0.16993444 ... 0.15880261 0.10117114 0.174619  ]\n",
            " [0.18924695 0.08190671 0.17091691 ... 0.15868844 0.09713349 0.18419762]\n",
            " ...\n",
            " [0.11203877 0.07777651 0.1376845  ... 0.13701524 0.09425112 0.3339912 ]\n",
            " [0.10850164 0.08034126 0.14296623 ... 0.14371787 0.08968264 0.32255232]\n",
            " [0.11024936 0.08156922 0.14090441 ... 0.14577933 0.0902662  0.3202964 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "true_labels = test_generator.classes\n",
        "ensemble_preds_labels = np.argmax(ensemble_predictions, axis=1)\n",
        "ensemble_accuracy = accuracy_score(true_labels, ensemble_preds_labels)\n",
        "print(f'Ensemble Model Accuracy: {ensemble_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vMvPfOckDdf",
        "outputId": "0c1e4c85-16ad-4528-d1c5-923b1e56c486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Model Accuracy: 0.34183673469387754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create ensemble model**"
      ],
      "metadata": {
        "id": "1rLOomQgVQ-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Layer\n",
        "\n",
        "# Ensure that the layers of the pre-trained models are not trainable\n",
        "model1.trainable = False\n",
        "model2.trainable = False\n",
        "model3.trainable = False\n",
        "\n",
        "# Define a custom layer to average the outputs\n",
        "class EnsembleLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(EnsembleLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Ensure inputs is a list of tensors\n",
        "        return tf.reduce_mean(inputs, axis=0)  # Averaging over the first dimension which is the batch dimension\n",
        "\n",
        "# Create a new model input\n",
        "input_shape = model1.input_shape[1:]  # Assumes all models have the same input shape\n",
        "model_input = Input(shape=input_shape)\n",
        "\n",
        "# Get outputs from each model\n",
        "output1 = model1(model_input)\n",
        "output2 = model2(model_input)\n",
        "output3 = model3(model_input)\n",
        "\n",
        "# Average the outputs using the custom EnsembleLayer\n",
        "ensemble_output = EnsembleLayer()([output1, output2, output3])\n",
        "\n",
        "# Create the ensemble model\n",
        "ensemble_model = Model(inputs=model_input, outputs=ensemble_output)\n",
        "\n",
        "\n",
        "# Save the model\n",
        "ensemble_model.save('ensemble_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXGjlKMDZExj",
        "outputId": "1dd6718f-9637-4e3a-9f85-d4bff435fc67"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build Gradio App**"
      ],
      "metadata": {
        "id": "HtUmLnWTk4KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "! pip install gradio matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p_WIR08CmMU5",
        "outputId": "c2f0a337-fce7-4970-d4c8-95fdf7826fb1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.40.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.2.0 (from gradio)\n",
            "  Downloading gradio_client-1.2.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.2.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.2.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.40.0-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.2.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.6/318.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.5.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.5-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.0\n",
            "    Uninstalling tomlkit-0.13.0:\n",
            "      Successfully uninstalled tomlkit-0.13.0\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.112.0 ffmpy-0.4.0 gradio-4.40.0 gradio-client-1.2.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.6 pydub-0.25.1 python-multipart-0.0.9 ruff-0.5.5 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 uvicorn-0.30.5 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Get 'order' of emotions\n",
        "dataset_folder='/content/Training/'\n",
        "sub_folders=os.listdir(dataset_folder)\n",
        "\n",
        "sub_folders\n",
        "print(sub_folders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tttuCWAnk9Ao",
        "outputId": "a444b3f4-7e84-41ca-e0ee-a53f6861f5d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happy', 'anger', 'sadness', 'fear', 'surprise', 'contempt', 'disgust']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import io\n",
        "\n",
        "# Load your models\n",
        "model1 = load_model('/content/model1.h5')\n",
        "model2 = load_model('/content/model2.h5')\n",
        "model3 = load_model('/content/model3.h5')\n",
        "\n",
        "# Define the class names for the 7 facial expressions (paste in output of previous cell into list contents)\n",
        "class_names = ['happy', 'anger', 'sadness', 'fear', 'surprise', 'contempt', 'disgust']\n",
        "\n",
        "# Define a function to make predictions and plot results\n",
        "def predict_and_plot(image):\n",
        "    try:\n",
        "        # Ensure the image is in RGB\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        # Preprocess the image for prediction\n",
        "        image_resized = image.resize((224, 224))  # Resize to the expected input size for the models\n",
        "        image_array = img_to_array(image_resized) / 255.0  # Normalize image\n",
        "        image_batch = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Make predictions with each model\n",
        "        predictions1 = model1.predict(image_batch)\n",
        "        predictions2 = model2.predict(image_batch)\n",
        "        predictions3 = model3.predict(image_batch)\n",
        "\n",
        "        # Average the predictions for ensemble prediction\n",
        "        ensemble_predictions = (predictions1 + predictions2 + predictions3) / 3\n",
        "        ensemble_predictions = ensemble_predictions.flatten()\n",
        "\n",
        "        # Create a bar plot\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.barh(class_names, ensemble_predictions, color='skyblue')\n",
        "        ax.set_xlim(0, 1)\n",
        "        ax.set_xlabel('Probability')\n",
        "        ax.set_title('Facial Expression Prediction')\n",
        "\n",
        "        # Convert plot to an image\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        plt.close(fig)\n",
        "\n",
        "        # Convert BytesIO to PIL Image\n",
        "        plot_image = Image.open(buf)\n",
        "\n",
        "        # Return the image and predictions\n",
        "        return {class_names[i]: float(ensemble_predictions[i]) for i in range(len(class_names))}, plot_image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return {class_name: 0.0 for class_name in class_names}, None\n",
        "\n",
        "# Create the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_and_plot,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[gr.Label(num_top_classes=7), gr.Image(type=\"pil\")],\n",
        "    title=\"Facial Expression Recognition\",\n",
        "    live=True\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "interface.launch(debug = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BnXFOoVvleky",
        "outputId": "871f7acf-bd29-4af6-87e1-3e27f9c6d778"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://121ed1ac8578bfda4a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://121ed1ac8578bfda4a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
            "An error occurred: 'NoneType' object has no attribute 'mode'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Load an example image\n",
        "test_image_path = '/content/Training/anger/S037_003_00000020.png'\n",
        "test_image = Image.open(test_image_path)\n",
        "\n",
        "\n",
        "# Run your function directly\n",
        "predictions, plot_buf = predict_and_plot(test_image)\n",
        "\n",
        "# Print the predictions to see what they look like\n",
        "print(predictions)\n",
        "\n",
        "# If plot_buf is not None, display the plot\n",
        "if plot_buf:\n",
        "    from IPython.display import display\n",
        "    from PIL import Image\n",
        "    display(Image.open(plot_buf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "bawqXjjZoO_V",
        "outputId": "ec0941de-3517-43a3-c467-f39da71bf3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
            "{'happy': 0.19320769608020782, 'fear': 0.08746010810136795, 'contempt': 0.18869780004024506, 'anger': 0.10114073753356934, 'sadness': 0.14772267639636993, 'disgust': 0.09997858852148056, 'surprise': 0.18179236352443695}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=640x480>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAABGlUlEQVR4nO3dd3gU5f7+8XtTN6RiqIGQkEIIAUITBQSkGVBQmiB6IHTOAVS6YIEE4YCIWEBpKgEVUTkgHKRIFakikIgSc2gBlCiCkFAkhczvD3/s1yUBCSUbMu/Xdc11ZWaemfnMzOLePlPWYhiGIQAAAJiGk6MLAAAAQOEiAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARC4y6WmpspisSghIaHAyyYkJMhisSg1NfW211XcxMXFyWKxOLoMh8hv34ODg9WzZ8/bto2ePXsqODj4tq0PwPURAIE74Eqwym8YPXq0o8srsCsB4FrDL7/84ugSi7W/HmsnJycFBATooYce0qZNmxxdWoGcOHFCcXFxSkxMdHQpgOm5OLoAoDgbP368KleubDetevXqt3UbQUFB+uOPP+Tq6npb15ufmTNnysvLK890Pz+/O75tR3vxxRcdGt5btWqlHj16yDAMHTlyRO+8846aN2+uL774Qm3atCn0elJSUuTkVLA+hBMnTig+Pl7BwcGqVauW3by5c+cqNzf3NlYI4HoIgMAd1KZNG9WrV++ObsNischqtd7RbVzRuXNnlSpVqlC2dS2GYejSpUvy8PAo1O26uLjIxcVx/8msUqWK/vGPf9jGO3TooJo1a+qNN964ZgC8dOmS3NzcChzUboS7u/ttXV9h/A8MgP/DJWDAAY4ePaqBAwcqIiJCHh4e8vf31+OPP57vvXhnz57V0KFDFRwcLHd3d1WsWFE9evTQqVOnJOV/D+B3332nnj17KiQkRFarVeXKlVPv3r11+vTpO7pfsbGxslqtSk5OtpseExOjkiVL6sSJE5L+7xL55s2bNWDAAPn7+8vHx0c9evTQmTNn7JYNDg5W27ZttWbNGtWrV08eHh6aPXu2pD+PzZAhQxQYGCh3d3eFhYXplVdeydOTtGjRItWtW1fe3t7y8fFRjRo19Oabb9rmZ2dnKz4+XuHh4bJarfL399cDDzygtWvX2trkdx9cTk6OXn75ZYWGhsrd3V3BwcF6/vnnlZmZme8+bNmyRfXr15fValVISIgWLFhwk0daqlGjhkqVKqUjR45IkjZt2iSLxaJFixbpxRdfVIUKFVSiRAllZGRIknbu3KnWrVvL19dXJUqUUNOmTbV169Y8692yZYvuvfdeWa1WhYaG2o711fK7B/B6n9VNmzbp3nvvlST16tXLdkn7yuc2v3sAL1y4oOHDh9vOb0REhKZOnSrDMOzaWSwWDR48WJ9//rmqV68ud3d3RUVFafXq1QU9rIBp0AMI3EHp6em2oHZFqVKltGvXLm3btk1PPPGEKlasqNTUVM2cOVMPPvig9u/frxIlSkiSzp8/r8aNGys5OVm9e/dWnTp1dOrUKS1fvlw//fTTNXvj1q5dq8OHD6tXr14qV66cfvjhB82ZM0c//PCDduzYcdMPM/z+++95prm4uNguAb/55pvasGGDYmNjtX37djk7O2v27Nn68ssv9cEHHyggIMBu2cGDB8vPz09xcXFKSUnRzJkzdfToUVuYuSIlJUXdunXTgAED1K9fP0VEROjixYtq2rSpfv75Zw0YMECVKlXStm3bNGbMGKWlpemNN96wHYtu3bqpRYsWeuWVVyRJycnJ2rp1q5599llJf4a7SZMmqW/fvqpfv74yMjL07bffas+ePWrVqtU1j0ffvn01f/58de7cWcOHD9fOnTs1adIkJScna+nSpXZtDx48qM6dO6tPnz6KjY3V+++/r549e6pu3bqKiooq8Lk4c+aMzpw5o7CwMLvpL7/8stzc3DRixAhlZmbKzc1NGzZsUJs2bVS3bl2NGzdOTk5Omjdvnpo3b66vv/5a9evXlyTt27dPDz30kEqXLq24uDjl5ORo3LhxKlu27N/W83ef1cjISI0fP15jx45V//791bhxY0lSw4YN812fYRh69NFHtXHjRvXp00e1atXSmjVrNHLkSP388896/fXX7dpv2bJFS5Ys0cCBA+Xt7a233npLnTp10rFjx+Tv71/g4wsUewaA227evHmGpHwHwzCMixcv5llm+/bthiRjwYIFtmljx441JBlLlizJ0z43N9cwDMM4cuSIIcmYN2+ebV5+6//4448NScbmzZvz1HnkyJHr7s+4ceOuuT8RERF2bdesWWNIMiZMmGAcPnzY8PLyMtq3b5/v8albt66RlZVlmz5lyhRDkrFs2TLbtKCgIEOSsXr1art1vPzyy4anp6fxv//9z2766NGjDWdnZ+PYsWOGYRjGs88+a/j4+Bg5OTnX3L/o6GjjkUceuaFjcEViYqIhyejbt69duxEjRhiSjA0bNuTZh78e+5MnTxru7u7G8OHDr7tdwzAMSUafPn2M3377zTh58qSxc+dOo0WLFoYk47XXXjMMwzA2btxoSDJCQkLszn9ubq4RHh5uxMTE2D4zhvHnZ6Ry5cpGq1atbNPat29vWK1W4+jRo7Zp+/fvN5ydnY2rvy6CgoKM2NhY2/iNfFZ37dqV57N6RWxsrBEUFGQb//zzz22fo7/q3LmzYbFYjIMHD9odHzc3N7tpSUlJhiRj+vTpebYFwDC4BAzcQW+//bbWrl1rN0iyu38tOztbp0+fVlhYmPz8/LRnzx7bvP/85z+Kjo5Whw4d8qz7er14f13/pUuXdOrUKd1///2SZLf+gvrPf/6TZ3/mzZtn1+ahhx7SgAEDNH78eHXs2FFWq/WalxH79+9vd+/Xv/71L7m4uGjlypV27SpXrqyYmBi7aZ999pkaN26skiVL6tSpU7ahZcuWunz5sjZv3izpzwdULly4YHc592p+fn764YcfdODAgRs+FldqHDZsmN304cOHS5K++OILu+nVqlWz9XpJUunSpRUREaHDhw/f0Pbee+89lS5dWmXKlNF9992nrVu3atiwYRoyZIhdu9jYWLvzn5iYqAMHDujJJ5/U6dOnbcfpwoULatGihTZv3qzc3FxdvnxZa9asUfv27VWpUiXb8pGRkXmOfX5u9rN6LStXrpSzs7OeeeYZu+nDhw+XYRhatWqV3fSWLVsqNDTUNl6zZk35+Pjc8PEFzIZLwMAdVL9+/XwfAvnjjz80adIkzZs3Tz///LPdPU3p6em2vw8dOqROnToVeLu///674uPjtWjRIp08edJu3l/XX1BNmjS5oYdApk6dqmXLlikxMVELFy5UmTJl8m0XHh5uN+7l5aXy5cvnuRfy6iepJenAgQP67rvvVLp06XzXfWW/Bw4cqE8//VRt2rRRhQoV9NBDD6lLly5q3bq1re348eP12GOPqUqVKqpevbpat26t7t27q2bNmtfcx6NHj8rJySnPJdhy5crJz89PR48etZv+11B1RcmSJfPc83gtjz32mAYPHiyLxSJvb29FRUXJ09MzT7urj9WVUBsbG3vNdaenpyszM1N//PFHnnMiSREREXlC+dVu9rN6LUePHlVAQIC8vb3tpkdGRtrm/9WtHl/AbAiAgAM8/fTTmjdvnoYMGaIGDRrI19dXFotFTzzxxG15FUaXLl20bds2jRw5UrVq1ZKXl5dyc3PVunXrQnnVxt69e20BbN++ferWrdstrS+/J35zc3PVqlUrjRo1Kt9lqlSpIkkqU6aMEhMTtWbNGq1atUqrVq3SvHnz1KNHD82fP1/Sn8H20KFDWrZsmb788ku9++67ev311zVr1iz17dv3urXdaO+Ws7NzvtONqx5ouJaKFSuqZcuWf9vu6mN15Xy/+uqreV69coWXl1eeB1fuNrd6fAGzIQACDrB48WLFxsbqtddes027dOmSzp49a9cuNDRU33//fYHWfebMGa1fv17x8fEaO3asbXpBLm/eigsXLqhXr16qVq2aGjZsqClTpqhDhw62J0D/6sCBA2rWrJlt/Pz580pLS9PDDz/8t9sJDQ3V+fPnbygUubm5qV27dmrXrp1yc3M1cOBAzZ49Wy+99JKtB++ee+5Rr1691KtXL50/f15NmjRRXFzcNQNgUFCQcnNzdeDAAVuvlCT9+uuvOnv2rIKCgv62rsJw5bKoj4/PdY9V6dKl5eHhke/nJCUl5Ya283ef1YJcCg4KCtK6det07tw5u17AH3/80TYfwM3jHkDAAZydnfP0TEyfPl2XL1+2m9apUyclJSXleaJUunbPxpWekKvnX3kq9k577rnndOzYMc2fP1/Tpk1TcHCwYmNj8+1hmjNnjrKzs23jM2fOVE5Ozg292LhLly7avn271qxZk2fe2bNnlZOTI0l5Xn3j5ORku7R7paar23h5eSksLOy6vWJXQurVx3XatGmSpEceeeRv96Ew1K1bV6GhoZo6darOnz+fZ/5vv/0m6c/PTUxMjD7//HMdO3bMNj85OTnfY3y1G/msXrlkffX/6OTn4Ycf1uXLlzVjxgy76a+//rosFotDXn4NFCf0AAIO0LZtW33wwQfy9fVVtWrVtH37dq1bty7P6ypGjhypxYsX6/HHH1fv3r1Vt25d/f7771q+fLlmzZql6OjoPOv28fFRkyZNNGXKFGVnZ6tChQr68ssvbe+LuxWLFy/O95dAWrVqpbJly2rDhg165513NG7cONWpU0eSNG/ePD344IN66aWXNGXKFLvlsrKy1KJFC3Xp0kUpKSl655139MADD+jRRx/921pGjhyp5cuXq23btrbXqVy4cEH79u3T4sWLlZqaqlKlSqlv3776/fff1bx5c1WsWFFHjx7V9OnTVatWLVvPXbVq1fTggw+qbt26uueee/Ttt99q8eLFGjx48DW3Hx0drdjYWM2ZM0dnz55V06ZN9c0332j+/Plq3769Xc+mIzk5Oendd99VmzZtFBUVpV69eqlChQr6+eeftXHjRvn4+Oi///2vJCk+Pl6rV69W48aNNXDgQOXk5Gj69OmKiorSd999d93t3MhnNTQ0VH5+fpo1a5a8vb3l6emp++67L997PNu1a6dmzZrphRdeUGpqqqKjo/Xll19q2bJlGjJkiN0DHwBuguMeQAaKryuvOdm1a1e+88+cOWP06tXLKFWqlOHl5WXExMQYP/74Y55XaxiGYZw+fdoYPHiwUaFCBcPNzc2oWLGiERsba5w6dcowjPxfA/PTTz8ZHTp0MPz8/AxfX1/j8ccfN06cOGFIMsaNG5enzlt5DYwkY+PGjUZGRoYRFBRk1KlTx8jOzrZbfujQoYaTk5Oxfft2u+1+9dVXRv/+/Y2SJUsaXl5exlNPPWWcPn3abtmgoKBrvqLl3LlzxpgxY4ywsDDDzc3NKFWqlNGwYUNj6tSpttfLLF682HjooYeMMmXKGG5ubkalSpWMAQMGGGlpabb1TJgwwahfv77h5+dneHh4GFWrVjUmTpxo94qaq18DYxiGkZ2dbcTHxxuVK1c2XF1djcDAQGPMmDHGpUuXbmgfmjZtajRt2vS6x94w/nzNyaBBg67b5sprYD777LN85+/du9fo2LGj4e/vb7i7uxtBQUFGly5djPXr19u1++qrr4y6desabm5uRkhIiDFr1qx89/1mPquGYRjLli0zqlWrZri4uNh9bq9+DYxh/Hl+hw4dagQEBBiurq5GeHi48eqrr9q9zuZ6xye/GgH8yWIY3CELoHAlJCSoV69e2rVr1x3/qTwAQF7cAwgAAGAyBEAAAACTIQACAACYDPcAAgAAmAw9gAAAACZDAAQAADAZAiAAAIDJ8EsgtyA3N1cnTpyQt7d3gX7jEgAAOI5hGDp37pwCAgLk5GTOvjAC4C04ceKEAgMDHV0GAAC4CcePH1fFihUdXYZDEABvgbe3t6Q/P0A+Pj4OrgYAANyIjIwMBQYG2r7HzYgAeAuuXPb18fEhAAIAcJcx8+1b5rzwDQAAYGIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAm4+LoAoqDaUmnZfXKcnQZxdro2qUcXQIAAMUGPYAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMpVgEwLi5OtWrVcnQZAAAARVqxCoAjRozQ+vXrHV0GAABAkebi6AL+KisrS25ubgVezjAMXb58WV5eXvLy8roDlQEAABQft9wDuHjxYtWoUUMeHh7y9/dXy5YtdeHCBT344IMaMmSIXdv27durZ8+etvHg4GC9/PLL6tGjh3x8fNS/f3+lpqbKYrFo0aJFatiwoaxWq6pXr66vvvrKttymTZtksVi0atUq1a1bV+7u7tqyZUueS8CbNm1S/fr15enpKT8/PzVq1EhHjx61zV+2bJnq1Kkjq9WqkJAQxcfHKycn51YPCQAAQJF2SwEwLS1N3bp1U+/evZWcnKxNmzapY8eOMgzjhtcxdepURUdHa+/evXrppZds00eOHKnhw4dr7969atCggdq1a6fTp0/bLTt69GhNnjxZycnJqlmzpt28nJwctW/fXk2bNtV3332n7du3q3///rJYLJKkr7/+Wj169NCzzz6r/fv3a/bs2UpISNDEiROvWWtmZqYyMjLsBgAAgLvNLV0CTktLU05Ojjp27KigoCBJUo0aNQq0jubNm2v48OG28dTUVEnS4MGD1alTJ0nSzJkztXr1ar333nsaNWqUre348ePVqlWrfNebkZGh9PR0tW3bVqGhoZKkyMhI2/z4+HiNHj1asbGxkqSQkBC9/PLLGjVqlMaNG5fvOidNmqT4+PgC7R8AAEBRc0s9gNHR0WrRooVq1Kihxx9/XHPnztWZM2cKtI569erlO71Bgwa2v11cXFSvXj0lJyff0LKSdM8996hnz56KiYlRu3bt9OabbyotLc02PykpSePHj7fdN+jl5aV+/fopLS1NFy9ezHedY8aMUXp6um04fvx4QXYVAACgSLilAOjs7Ky1a9dq1apVqlatmqZPn66IiAgdOXJETk5OeS4FZ2dn51mHp6fnTW//75adN2+etm/froYNG+qTTz5RlSpVtGPHDknS+fPnFR8fr8TERNuwb98+HThwQFarNd/1ubu7y8fHx24AAAC429zyQyAWi0WNGjVSfHy89u7dKzc3Ny1dulSlS5e263G7fPmyvv/++xte75WgJv15P9/u3bvtLuHeqNq1a2vMmDHatm2bqlevroULF0qS6tSpo5SUFIWFheUZnJyK1dtxAAAA7NzSPYA7d+7U+vXr9dBDD6lMmTLauXOnfvvtN0VGRsrT01PDhg3TF198odDQUE2bNk1nz5694XW//fbbCg8PV2RkpF5//XWdOXNGvXv3vuHljxw5ojlz5ujRRx9VQECAUlJSdODAAfXo0UOSNHbsWLVt21aVKlVS586d5eTkpKSkJH3//feaMGFCQQ8FAADAXeOWAqCPj482b96sN954QxkZGQoKCtJrr72mNm3aKDs7W0lJSerRo4dcXFw0dOhQNWvW7IbXPXnyZE2ePFmJiYkKCwvT8uXLVapUqRtevkSJEvrxxx81f/58nT59WuXLl9egQYM0YMAASVJMTIxWrFih8ePH65VXXpGrq6uqVq2qvn37Fvg4AAAA3E0sRkHe2VIIUlNTVblyZe3du7fI/6xbRkaGfH19NW7zYVm9vB1dTrE2uvaNh38AAK7nyvd3enq6ae/n52Y3AAAAkyEAAgAAmEyR+i1g6c+fhytiV6UBAACKFXoAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDJF7qfg7kbDov3l4+Pj6DIAAABuCD2AAAAAJkMABAAAMBkCIAAAgMkQAAEAAEyGAAgAAGAyBEAAAACTIQACAACYDAEQAADAZAiAAAAAJsMvgdwG05JOy+qV5egybsno2qUcXQIAACgk9AACAACYDAEQAADAZAiAAAAAJkMABAAAMBkCIAAAgMkQAAEAAEyGAAgAAGAyBEAAAACTIQACAACYDAEQAADAZAiAAAAAJkMABAAAMBkCIAAAgMkUagB88MEHNWTIEElScHCw3njjjcLcPAAAACS5OGrDu3btkqenp6M2byc1NVWVK1fW3r17VatWLUeXAwAAcEc5LACWLl3aUZsGAAAwtTt2CfjChQvq0aOHvLy8VL58eb322mt28/96CdgwDMXFxalSpUpyd3dXQECAnnnmGVvbtLQ0PfLII/Lw8FDlypW1cOFCu+VTU1NlsViUmJhoW+bs2bOyWCzatGmTJOnMmTN66qmnVLp0aXl4eCg8PFzz5s2TJFWuXFmSVLt2bVksFj344IN35JgAAAAUBXesB3DkyJH66quvtGzZMpUpU0bPP/+89uzZk+8l1v/85z96/fXXtWjRIkVFRemXX35RUlKSbX6PHj106tQpbdq0Sa6urho2bJhOnjxZoHpeeukl7d+/X6tWrVKpUqV08OBB/fHHH5Kkb775RvXr19e6desUFRUlNze3W9p3AACAouyOBMDz58/rvffe04cffqgWLVpIkubPn6+KFSvm2/7YsWMqV66cWrZsKVdXV1WqVEn169eXJP34449at26ddu3apXr16kmS3n33XYWHhxeopmPHjql27dq2dQQHB9vmXbkc7e/vr3Llyl1zHZmZmcrMzLSNZ2RkFKgGAACAouCOXAI+dOiQsrKydN9999mm3XPPPYqIiMi3/eOPP64//vhDISEh6tevn5YuXaqcnBxJUkpKilxcXFSnTh1b+7CwMJUsWbJANf3rX//SokWLVKtWLY0aNUrbtm0r8H5NmjRJvr6+tiEwMLDA6wAAAHC0IvEewMDAQKWkpOidd96Rh4eHBg4cqCZNmig7O/uGlndy+nM3DMOwTbt62TZt2ujo0aMaOnSoTpw4oRYtWmjEiBEFqnPMmDFKT0+3DcePHy/Q8gAAAEXBHQmAoaGhcnV11c6dO23Tzpw5o//973/XXMbDw0Pt2rXTW2+9pU2bNmn79u3at2+fIiIilJOTo71799raHjx4UGfOnLGNX7mEm5aWZpv21wdC/touNjZWH374od544w3NmTNHkmz3/F2+fPm6++Xu7i4fHx+7AQAA4G5zR+4B9PLyUp8+fTRy5Ej5+/urTJkyeuGFF2w9dVdLSEjQ5cuXdd9996lEiRL68MMP5eHhoaCgIPn7+6tly5bq37+/Zs6cKVdXVw0fPlweHh6yWCyS/gyP999/vyZPnqzKlSvr5MmTevHFF+22MXbsWNWtW1dRUVHKzMzUihUrFBkZKUkqU6aMPDw8tHr1alWsWFFWq1W+vr534tAAAAA43B27BPzqq6+qcePGateunVq2bKkHHnhAdevWzbetn5+f5s6dq0aNGqlmzZpat26d/vvf/8rf31+StGDBApUtW1ZNmjRRhw4d1K9fP3l7e8tqtdrW8f777ysnJ0d169bVkCFDNGHCBLttuLm5acyYMapZs6aaNGkiZ2dnLVq0SJLk4uKit956S7Nnz1ZAQIAee+yxO3RUAAAAHM9i/PXGubvETz/9pMDAQK1bt872lLEjZGRkyNfXV+M2H5bVy9thddwOo2uXcnQJAAAUiivf3+np6aa9ncthvwRSEBs2bND58+dVo0YNpaWladSoUQoODlaTJk0cXRoAAMBd564IgNnZ2Xr++ed1+PBheXt7q2HDhvroo4/k6urq6NIAAADuOndFAIyJiVFMTIyjywAAACgWisR7AAEAAFB4CIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmc1f8FFxRNyzaXz4+Po4uAwAA4IbQAwgAAGAyBEAAAACTIQACAACYDAEQAADAZAiAAAAAJkMABAAAMBkCIAAAgMkQAAEAAEyGAAgAAGAy/BLIbTAt6bSsXlmOLqPIGl27lKNLAAAAf0EPIAAAgMkQAAEAAEyGAAgAAGAyBEAAAACTIQACAACYDAEQAADAZAiAAAAAJkMABAAAMBkCIAAAgMkQAAEAAEyGAAgAAGAyBEAAAACTIQACAACYTJELgBaLRZ9//rmjywAAACi2ilwABAAAwJ1FAAQAADCZWw6AixcvVo0aNeTh4SF/f3+1bNlSFy5c0K5du9SqVSuVKlVKvr6+atq0qfbs2WO37IEDB9SkSRNZrVZVq1ZNa9eutZufmpoqi8WiJUuWqFmzZipRooSio6O1fft2u3ZbtmxR48aN5eHhocDAQD3zzDO6cOGCbf4777yj8PBwWa1WlS1bVp07d/7b+gEAAIqrWwqAaWlp6tatm3r37q3k5GRt2rRJHTt2lGEYOnfunGJjY7Vlyxbt2LFD4eHhevjhh3Xu3DlJUm5urjp27Cg3Nzft3LlTs2bN0nPPPZfvdl544QWNGDFCiYmJqlKlirp166acnBxJ0qFDh9S6dWt16tRJ3333nT755BNt2bJFgwcPliR9++23euaZZzR+/HilpKRo9erVatKkyd/WDwAAUFxZjFtIO3v27FHdunWVmpqqoKCg67bNzc2Vn5+fFi5cqLZt2+rLL7/UI488oqNHjyogIECStHr1arVp00ZLly5V+/btlZqaqsqVK+vdd99Vnz59JEn79+9XVFSUkpOTVbVqVfXt21fOzs6aPXu2bVtbtmxR06ZNdeHCBa1cuVK9evXSTz/9JG9v75uuX5IyMzOVmZlpG8/IyFBgYKDGbT4sq5f3dZY0t9G1Szm6BAAAbDIyMuTr66v09HT5+Pg4uhyHuKUewOjoaLVo0UI1atTQ448/rrlz5+rMmTOSpF9//VX9+vVTeHi4fH195ePjo/Pnz+vYsWOSpOTkZAUGBtrCnyQ1aNAg3+3UrFnT9nf58uUlSSdPnpQkJSUlKSEhQV5eXrYhJiZGubm5OnLkiFq1aqWgoCCFhISoe/fu+uijj3Tx4sW/rT8/kyZNkq+vr20IDAy8haMHAADgGLcUAJ2dnbV27VqtWrVK1apV0/Tp0xUREaEjR44oNjZWiYmJevPNN7Vt2zYlJibK399fWVlZBd6Oq6ur7W+LxSLpzx5FSTp//rwGDBigxMRE25CUlKQDBw4oNDRU3t7e2rNnjz7++GOVL19eY8eOVXR0tM6ePXvd+vMzZswYpaen24bjx4/fxFEDAABwrFt+CMRisahRo0aKj4/X3r175ebmpqVLl2rr1q165pln9PDDDysqKkru7u46deqUbbnIyEgdP35caWlptmk7duwo8Pbr1Kmj/fv3KywsLM/g5uYmSXJxcVHLli01ZcoUfffdd0pNTdWGDRuuW39+3N3d5ePjYzcAAADcbVxuZeGdO3dq/fr1euihh1SmTBnt3LlTv/32myIjIxUeHq4PPvhA9erVU0ZGhkaOHCkPDw/bsi1btlSVKlUUGxurV199VRkZGXrhhRcKXMNzzz2n+++/X4MHD1bfvn3l6emp/fv3a+3atZoxY4ZWrFihw4cPq0mTJipZsqRWrlyp3NxcRUREXLd+AACA4uqWAqCPj482b96sN954QxkZGQoKCtJrr72mNm3aqFy5curfv7/q1KmjwMBA/fvf/9aIESNsyzo5OWnp0qXq06eP6tevr+DgYL311ltq3bp1gWqoWbOmvvrqK73wwgtq3LixDMNQaGiounbtKkny8/PTkiVLFBcXp0uXLik8PFwff/yx7UGSa9UPAABQXN3SU8Bmd+UpIp4Cvj6eAgYAFCU8BcwvgQAAAJgOARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATMbF0QUUB8Oi/eXj4+PoMgAAAG4IPYAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmwy+B3AbTkk7L6pXl6DJuyejapRxdAgAAKCT0AAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEwGvIzs52dAkAAAB3hMMD4OrVq/XAAw/Iz89P/v7+atu2rQ4dOiRJSk1NlcVi0ZIlS9SsWTOVKFFC0dHR2r59u9065s6dq8DAQJUoUUIdOnTQtGnT5OfnZ9dm2bJlqlOnjqxWq0JCQhQfH6+cnBzbfIvFopkzZ+rRRx+Vp6enJk6ceMf3HQAAwBEcHgAvXLigYcOG6dtvv9X69evl5OSkDh06KDc319bmhRde0IgRI5SYmKgqVaqoW7dutvC2detW/fOf/9Szzz6rxMREtWrVKk94+/rrr9WjRw89++yz2r9/v2bPnq2EhIQ87eLi4tShQwft27dPvXv3zlNrZmamMjIy7AYAAIC7jcUwDMPRRfzVqVOnVLp0ae3bt09eXl6qXLmy3n33XfXp00eStH//fkVFRSk5OVlVq1bVE088ofPnz2vFihW2dfzjH//QihUrdPbsWUlSy5Yt1aJFC40ZM8bW5sMPP9SoUaN04sQJSX/2AA4ZMkSvv/76NWuLi4tTfHx8nunjNh+W1cv7duy+w4yuXcrRJQAAUCgyMjLk6+ur9PR0+fj4OLoch3B4D+CBAwfUrVs3hYSEyMfHR8HBwZKkY8eO2drUrFnT9nf58uUlSSdPnpQkpaSkqH79+nbrvHo8KSlJ48ePl5eXl23o16+f0tLSdPHiRVu7evXqXbfWMWPGKD093TYcP3684DsMAADgYC6OLqBdu3YKCgrS3LlzFRAQoNzcXFWvXl1ZWVm2Nq6urra/LRaLJNldIv4758+fV3x8vDp27JhnntVqtf3t6el53fW4u7vL3d39hrcLAABQFDk0AJ4+fVopKSmaO3euGjduLEnasmVLgdYRERGhXbt22U27erxOnTpKSUlRWFjYrRUMAABQDDg0AJYsWVL+/v6aM2eOypcvr2PHjmn06NEFWsfTTz+tJk2aaNq0aWrXrp02bNigVatW2XoKJWns2LFq27atKlWqpM6dO8vJyUlJSUn6/vvvNWHChNu9WwAAAEWaQ+8BdHJy0qJFi7R7925Vr15dQ4cO1auvvlqgdTRq1EizZs3StGnTFB0drdWrV2vo0KF2l3ZjYmK0YsUKffnll7r33nt1//336/XXX1dQUNDt3iUAAIAir8g9BXw79OvXTz/++KO+/vrrO7qdK08R8RQwAAB3D54CLgIPgdwOU6dOVatWreTp6alVq1Zp/vz5eueddxxdFgAAQJFULALgN998oylTpujcuXMKCQnRW2+9pb59+zq6LAAAgCKpWATATz/91NElAAAA3DUc/iJoAAAAFC4CIAAAgMkQAAEAAEyGAAgAAGAyBEAAAACTIQACAACYDAEQAADAZAiAAAAAJkMABAAAMBkCIAAAgMkUi5+Cc7Rh0f7y8fFxdBkAAAA3hB5AAAAAkyEAAgAAmAwBEAAAwGQIgAAAACZDAAQAADAZAiAAAIDJEAABAABMhgAIAABgMgRAAAAAk+GXQG6DaUmnZfXKcnQZpjK6dilHlwAAwF2LHkAAAACTIQACAACYDAEQAADAZAiAAAAAJkMABAAAMBkCIAAAgMkQAAEAAEyGAAgAAGAyBEAAAACTIQACAACYDAEQAADAZAiAAAAAJkMABAAAMBkCIAAAgMk4JAAGBwfrjTfecMSm8xUXF6datWo5ugwAAIBCQQ8gAACAyeQbAHNzczVlyhSFhYXJ3d1dlSpV0sSJEyVJ+/btU/PmzeXh4SF/f3/1799f58+fty3bs2dPtW/fXlOnTlX58uXl7++vQYMGKTs7W5L04IMP6ujRoxo6dKgsFossFott2S1btqhx48by8PBQYGCgnnnmGV24cME2Pzg4WBMmTFCPHj3k5eWloKAgLV++XL/99psee+wxeXl5qWbNmvr2229tyyQkJMjPz0+ff/65wsPDZbVaFRMTo+PHj9vmx8fHKykpyVZPQkLC7TvCAAAARUy+AXDMmDGaPHmyXnrpJe3fv18LFy5U2bJldeHCBcXExKhkyZLatWuXPvvsM61bt06DBw+2W37jxo06dOiQNm7cqPnz5yshIcEWqpYsWaKKFStq/PjxSktLU1pamiTp0KFDat26tTp16qTvvvtOn3zyibZs2ZJn3a+//roaNWqkvXv36pFHHlH37t3Vo0cP/eMf/9CePXsUGhqqHj16yDAM2zIXL17UxIkTtWDBAm3dulVnz57VE088IUnq2rWrhg8frqioKFs9Xbt2vW0HGAAAoKhxuXrCuXPn9Oabb2rGjBmKjY2VJIWGhuqBBx7Q3LlzdenSJS1YsECenp6SpBkzZqhdu3Z65ZVXVLZsWUlSyZIlNWPGDDk7O6tq1ap65JFHtH79evXr10/33HOPnJ2d5e3trXLlytm2O2nSJD311FMaMmSIJCk8PFxvvfWWmjZtqpkzZ8pqtUqSHn74YQ0YMECSNHbsWM2cOVP33nuvHn/8cUnSc889pwYNGujXX3+1rT87O1szZszQfffdJ0maP3++IiMj9c0336h+/fry8vKSi4uLXT35yczMVGZmpm08IyOjgIcbAADA8fL0ACYnJyszM1MtWrTI0zg5OVnR0dG28CdJjRo1Um5urlJSUmzToqKi5OzsbBsvX768Tp48ed1CkpKSlJCQIC8vL9sQExOj3NxcHTlyxNauZs2atr+vBM4aNWrkmfbX7bm4uOjee++1jVetWlV+fn5KTk6+bk1XmzRpknx9fW1DYGBggZYHAAAoCvL0AHp4eNzySl1dXe3GLRaLcnNzr7vM+fPnNWDAAD3zzDN55lWqVCnfdV+5fzC/aX+3vZsxZswYDRs2zDaekZFBCAQAAHedPD2A4eHh8vDw0Pr16/M0joyMVFJSkt2DGVu3bpWTk5MiIiJueKNubm66fPmy3bQ6depo//79CgsLyzO4ubkVZJ/yyMnJsXswJCUlRWfPnlVkZOQ168mPu7u7fHx87AYAAIC7TZ4AaLVa9dxzz2nUqFFasGCBDh06pB07dui9997TU089JavVqtjYWH3//ffauHGjnn76aXXv3t126fVGBAcHa/Pmzfr555916tQpSX/eu7dt2zYNHjxYiYmJOnDggJYtW5bnIZCb4erqqqefflo7d+7U7t271bNnT91///2qX7++rZ4jR44oMTFRp06dsrvPDwAAoLjJ9yngl156ScOHD9fYsWMVGRmprl276uTJkypRooTWrFmj33//Xffee686d+6sFi1aaMaMGQXa6Pjx45WamqrQ0FCVLl1a0p/39n311Vf63//+p8aNG6t27doaO3asAgICbnknS5Qooeeee05PPvmkGjVqJC8vL33yySe2+Z06dVLr1q3VrFkzlS5dWh9//PEtbxMAAKCoshh/fV9KMZSQkKAhQ4bo7Nmzt33dGRkZ8vX11bjNh2X18r7t68e1ja5dytElAADuUle+v9PT0017Oxe/BAIAAGAyBEAAAACTKfYBsGfPnnfk8i8AAMDdqtgHQAAAANgjAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkXBxdQHEwLNpfPj4+ji4DAADghtADCAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYXQd8G05JOy+qV5egy/tbo2qUcXQIAACgC6AEEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJjMXRcADcNQ//79dc8998hisSgxMdHRJQEAANxVXBxdQEGtXr1aCQkJ2rRpk0JCQlSqVClHlwQAAHBXuesC4KFDh1S+fHk1bNjwjm0jKytLbm5ud2z9AAAAjnRXXQLu2bOnnn76aR07dkwWi0XBwcHKzc3VpEmTVLlyZXl4eCg6OlqLFy+2LXP58mX16dPHNj8iIkJvvvlmnvW2b99eEydOVEBAgCIiIgp71wAAAArNXdUD+Oabbyo0NFRz5szRrl275OzsrEmTJunDDz/UrFmzFB4ers2bN+sf//iHSpcuraZNmyo3N1cVK1bUZ599Jn9/f23btk39+/dX+fLl1aVLF9u6169fLx8fH61du/aa28/MzFRmZqZtPCMj447uLwAAwJ1wVwVAX19feXt7y9nZWeXKlVNmZqb+/e9/a926dWrQoIEkKSQkRFu2bNHs2bPVtGlTubq6Kj4+3raOypUra/v27fr000/tAqCnp6fefffd6176nTRpkt26AAAA7kZ3VQC82sGDB3Xx4kW1atXKbnpWVpZq165tG3/77bf1/vvv69ixY/rjjz+UlZWlWrVq2S1To0aNv73vb8yYMRo2bJhtPCMjQ4GBgbe+IwAAAIXorg6A58+flyR98cUXqlChgt08d3d3SdKiRYs0YsQIvfbaa2rQoIG8vb316quvaufOnXbtPT09/3Z77u7utvUCAADcre7qAFitWjW5u7vr2LFjatq0ab5ttm7dqoYNG2rgwIG2aYcOHSqsEgEAAIqcuzoAent7a8SIERo6dKhyc3P1wAMPKD09XVu3bpWPj49iY2MVHh6uBQsWaM2aNapcubI++OAD7dq1S5UrV3Z0+QAAAA5xVwdASXr55ZdVunRpTZo0SYcPH5afn5/q1Kmj559/XpI0YMAA7d27V127dpXFYlG3bt00cOBArVq1ysGVAwAAOIbFMAzD0UXcrTIyMuTr66txmw/L6uXt6HL+1uja/GoKAABXvr/T09Pl4+Pj6HIc4q56ETQAAABuHQEQAADAZAiAAAAAJkMABAAAMBkCIAAAgMkQAAEAAEyGAAgAAGAyBEAAAACTIQACAACYDAEQAADAZAiAAAAAJkMABAAAMBkCIAAAgMm4OLqA4mBYtL98fHwcXQYAAMANoQcQAADAZAiAAAAAJkMABAAAMBkCIAAAgMkQAAEAAEyGAAgAAGAyBEAAAACTIQACAACYDAEQAADAZPglkNtgWtJpWb2yHF2GKY2uXcrRJQAAcNehBxAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATKbQA+CDDz6oIUOGFPZmAQAA8P/RAwgAAGAyBEAAAACTcUgAzM3N1ahRo3TPPfeoXLlyiouLs82bNm2aatSoIU9PTwUGBmrgwIE6f/68bX5CQoL8/Pz0+eefKzw8XFarVTExMTp+/LitTVxcnGrVqqXZs2crMDBQJUqUUJcuXZSeni5J2rx5s1xdXfXLL7/Y1TVkyBA1btz4zu48AACAgzkkAM6fP1+enp7auXOnpkyZovHjx2vt2rV/FuTkpLfeeks//PCD5s+frw0bNmjUqFF2y1+8eFETJ07UggULtHXrVp09e1ZPPPGEXZuDBw/q008/1X//+1+tXr1ae/fu1cCBAyVJTZo0UUhIiD744ANb++zsbH300Ufq3bv3Hd57AAAAx3JIAKxZs6bGjRun8PBw9ejRQ/Xq1dP69esl/dkL16xZMwUHB6t58+aaMGGCPv30U7vls7OzNWPGDDVo0EB169bV/PnztW3bNn3zzTe2NpcuXdKCBQtUq1YtNWnSRNOnT9eiRYtsvX59+vTRvHnzbO3/+9//6tKlS+rSpcs1687MzFRGRobdAAAAcLdxWAD8q/Lly+vkyZOSpHXr1qlFixaqUKGCvL291b17d50+fVoXL160tXdxcdG9995rG69atar8/PyUnJxsm1apUiVVqFDBNt6gQQPl5uYqJSVFktSzZ08dPHhQO3bskPTnpeUuXbrI09PzmnVPmjRJvr6+tiEwMPAWjgIAAIBjOCQAurq62o1bLBbl5uYqNTVVbdu2Vc2aNfWf//xHu3fv1ttvvy1JysrKuq01lClTRu3atdO8efP066+/atWqVX97+XfMmDFKT0+3DX+97xAAAOBu4eLoAv5q9+7dys3N1WuvvSYnpz+z6dWXfyUpJydH3377rerXry9JSklJ0dmzZxUZGWlrc+zYMZ04cUIBAQGSpB07dsjJyUkRERG2Nn379lW3bt1UsWJFhYaGqlGjRtetz93dXe7u7re8nwAAAI5UpF4DExYWpuzsbE2fPl2HDx/WBx98oFmzZuVp5+rqqqefflo7d+7U7t271bNnT91///22QChJVqtVsbGxSkpK0tdff61nnnlGXbp0Ubly5WxtYmJi5OPjowkTJqhXr16Fso8AAACOVqQCYHR0tKZNm6ZXXnlF1atX10cffaRJkyblaVeiRAk999xzevLJJ9WoUSN5eXnpk08+sWsTFhamjh076uGHH9ZDDz2kmjVr6p133rFr4+TkpJ49e+ry5cvq0aPHHd03AACAosJiGIbh6CIKIiEhQUOGDNHZs2ev2SYuLk6ff/65EhMT/3Z9ffr00W+//ably5cXuJaMjAz5+vpq3ObDsnp5F3h53LrRtUs5ugQAwF3myvd3enq6fHx8HF2OQxSpewALU3p6uvbt26eFCxfeVPgDAAC4W5k2AD722GP65ptv9M9//lOtWrVydDkAAACF5q67BFyUcAnY8bgEDAAoKC4BF7GHQAAAAHDnEQABAABMhgAIAABgMgRAAAAAkyEAAgAAmAwBEAAAwGQIgAAAACZDAAQAADAZAiAAAIDJEAABAABMxrS/BXw7DYv2N+1PyQAAgLsPPYAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJgMARAAAMBkCIAAAAAmQwAEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEQAAAAJMhAAIAAJiMi6MLuJsZhiFJysjIcHAlAADgRl353r7yPW5GBMBbcPr0aUlSYGCggysBAAAFdfr0afn6+jq6DIcgAN6Ce+65R5J07Ngx036AioqMjAwFBgbq+PHj8vHxcXQ5psa5KFo4H0UH56LoSE9PV6VKlWzf42ZEALwFTk5/3kLp6+vLP+YiwsfHh3NRRHAuihbOR9HBuSg6rnyPm5F59xwAAMCkCIAAAAAmQwC8Be7u7ho3bpzc3d0dXYrpcS6KDs5F0cL5KDo4F0UH50KyGGZ+BhoAAMCE6AEEAAAwGQIgAACAyRAAAQAATIYACAAAYDIEwL/x9ttvKzg4WFarVffdd5+++eab67b/7LPPVLVqVVmtVtWoUUMrV64spEqLv4Kci7lz56px48YqWbKkSpYsqZYtW/7tucONK+i/iysWLVoki8Wi9u3b39kCTaSg5+Ls2bMaNGiQypcvL3d3d1WpUoX/Tt1GBT0fb7zxhiIiIuTh4aHAwEANHTpUly5dKqRqi6/NmzerXbt2CggIkMVi0eeff/63y2zatEl16tSRu7u7wsLClJCQcMfrdCgD17Ro0SLDzc3NeP/9940ffvjB6Nevn+Hn52f8+uuv+bbfunWr4ezsbEyZMsXYv3+/8eKLLxqurq7Gvn37Crny4qeg5+LJJ5803n77bWPv3r1GcnKy0bNnT8PX19f46aefCrny4qeg5+KKI0eOGBUqVDAaN25sPPbYY4VTbDFX0HORmZlp1KtXz3j44YeNLVu2GEeOHDE2bdpkJCYmFnLlxVNBz8dHH31kuLu7Gx999JFx5MgRY82aNUb58uWNoUOHFnLlxc/KlSuNF154wViyZIkhyVi6dOl12x8+fNgoUaKEMWzYMGP//v3G9OnTDWdnZ2P16tWFU7ADEACvo379+sagQYNs45cvXzYCAgKMSZMm5du+S5cuxiOPPGI37b777jMGDBhwR+s0g4Kei6vl5OQY3t7exvz58+9UiaZxM+ciJyfHaNiwofHuu+8asbGxBMDbpKDnYubMmUZISIiRlZVVWCWaSkHPx6BBg4zmzZvbTRs2bJjRqFGjO1qn2dxIABw1apQRFRVlN61r165GTEzMHazMsbgEfA1ZWVnavXu3WrZsaZvm5OSkli1bavv27fkus337drv2khQTE3PN9rgxN3Murnbx4kVlZ2eb+oe/b4ebPRfjx49XmTJl1KdPn8Io0xRu5lwsX75cDRo00KBBg1S2bFlVr15d//73v3X58uXCKrvYupnz0bBhQ+3evdt2mfjw4cNauXKlHn744UKpGf/HjN/fLo4uoKg6deqULl++rLJly9pNL1u2rH788cd8l/nll1/ybf/LL7/csTrN4GbOxdWee+45BQQE5PkHjoK5mXOxZcsWvffee0pMTCyECs3jZs7F4cOHtWHDBj311FNauXKlDh48qIEDByo7O1vjxo0rjLKLrZs5H08++aROnTqlBx54QIZhKCcnR//85z/1/PPPF0bJ+ItrfX9nZGTojz/+kIeHh4Mqu3PoAUSxN3nyZC1atEhLly6V1Wp1dDmmcu7cOXXv3l1z585VqVKlHF2O6eXm5qpMmTKaM2eO6tatq65du+qFF17QrFmzHF2aKW3atEn//ve/9c4772jPnj1asmSJvvjiC7388suOLg0mQA/gNZQqVUrOzs769ddf7ab/+uuvKleuXL7LlCtXrkDtcWNu5lxcMXXqVE2ePFnr1q1TzZo172SZplDQc3Ho0CGlpqaqXbt2tmm5ubmSJBcXF6WkpCg0NPTOFl1M3cy/i/Lly8vV1VXOzs62aZGRkfrll1+UlZUlNze3O1pzcXYz5+Oll15S9+7d1bdvX0lSjRo1dOHCBfXv318vvPCCnJzooyks1/r+9vHxKZa9fxI9gNfk5uamunXrav369bZpubm5Wr9+vRo0aJDvMg0aNLBrL0lr1669ZnvcmJs5F5I0ZcoUvfzyy1q9erXq1atXGKUWewU9F1WrVtW+ffuUmJhoGx599FE1a9ZMiYmJCgwMLMzyi5Wb+XfRqFEjHTx40BbCJel///ufypcvT/i7RTdzPi5evJgn5F0J54Zh3LlikYcpv78d/RRKUbZo0SLD3d3dSEhIMPbv32/079/f8PPzM3755RfDMAyje/fuxujRo23tt27dari4uBhTp041kpOTjXHjxvEamNukoOdi8uTJhpubm7F48WIjLS3NNpw7d85Ru1BsFPRcXI2ngG+fgp6LY8eOGd7e3sbgwYONlJQUY8WKFUaZMmWMCRMmOGoXipWCno9x48YZ3t7exscff2wcPnzY+PLLL43Q0FCjS5cujtqFYuPcuXPG3r17jb179xqSjGnTphl79+41jh49ahiGYYwePdro3r27rf2V18CMHDnSSE5ONt5++21eA2N206dPNypVqmS4ubkZ9evXN3bs2GGb17RpUyM2Ntau/aeffmpUqVLFcHNzM6KioowvvviikCsuvgpyLoKCggxJeYZx48YVfuHFUEH/XfwVAfD2Kui52LZtm3HfffcZ7u7uRkhIiDFx4kQjJyenkKsuvgpyPrKzs424uDgjNDTUsFqtRmBgoDFw4EDjzJkzhV94MbNx48Z8vwOuHP/Y2FijadOmeZapVauW4ebmZoSEhBjz5s0r9LoLk8Uw6GcGAAAwE+4BBAAAMBkCIAAAgMkQAAEAAEyGAAgAAGAyBEAAAACTIQACAACYDAEQAADAZAiAAIq1nj17qn379re0jtTUVFksFiUmJl6zzaZNm2SxWHT27FlJUkJCgvz8/Gzz4+LiVKtWrVuqAwBuFwIggCKjZ8+eslgsslgscnNzU1hYmMaPH6+cnBxHl/a3GjZsqLS0NPn6+uY7f8SIEXa/NXo7gikA3CwXRxcAAH/VunVrzZs3T5mZmVq5cqUGDRokV1dXjRkzxq5dVlaW3NzcHFRlXm5ubipXrtw153t5ecnLy6sQKwKAa6MHEECR4u7urnLlyikoKEj/+te/1LJlSy1fvtzWYzZx4kQFBAQoIiJCkrRv3z41b95cHh4e8vf3V//+/XX+/Pk8642Pj1fp0qXl4+Ojf/7zn8rKyrLNW716tR544AH5+fnJ399fbdu21aFDh/Ks48cff1TDhg1ltVpVvXp1ffXVV7Z5V18CvtpfLwHHxcVp/vz5WrZsma3Hc9OmTWrevLkGDx5st9xvv/0mNzc3u95DALhVBEAARZqHh4ctrK1fv14pKSlau3atVqxYoQsXLigmJkYlS5bUrl279Nlnn2ndunV5QtT69euVnJysTZs26eOPP9aSJUsUHx9vm3/hwgUNGzZM3377rdavXy8nJyd16NBBubm5dusZOXKkhg8frr1796pBgwZq166dTp8+XeB9GjFihLp06aLWrVsrLS1NaWlpatiwofr27auFCxcqMzPT1vbDDz9UhQoV1Lx58wJvBwCuhQAIoEgyDEPr1q3TmjVrbOHH09NT7777rqKiohQVFaWFCxfq0qVLWrBggapXr67mzZtrxowZ+uCDD/Trr7/a1uXm5qb3339fUVFReuSRRzR+/Hi99dZbtoDXqVMndezYUWFhYapVq5bef/997du3T/v377erafDgwerUqZMiIyM1c+ZM+fr66r333ivwvnl5ecnDw8PW21muXDm5ubmpY8eOkqRly5bZ2iYkJNjujQSA24UACKBIWbFihby8vGS1WtWmTRt17dpVcXFxkqQaNWrY3feXnJys6OhoeXp62qY1atRIubm5SklJsU2Ljo5WiRIlbOMNGjTQ+fPndfz4cUnSgQMH1K1bN4WEhMjHx0fBwcGSpGPHjtnV1qBBA9vfLi4uqlevnpKTk2/bvlutVnXv3l3vv/++JGnPnj36/vvv1bNnz9u2DQCQeAgEQBHTrFkzzZw5U25ubgoICJCLy//9Z+qvQe92ateunYKCgjR37lwFBAQoNzdX1atXt7tPsLD07dtXtWrV0k8//aR58+apefPmCgoKKvQ6ABRv9AACKFI8PT0VFhamSpUq2YW//ERGRiopKUkXLlywTdu6daucnJxsD4lIUlJSkv744w/b+I4dO+Tl5aXAwECdPn1aKSkpevHFF9WiRQtFRkbqzJkz+W5vx44dtr9zcnK0e/duRUZG3tR+urm56fLly3mm16hRQ/Xq1dPcuXO1cOFC9e7d+6bWDwDXQwAEcNd66qmnZLVaFRsbq++//14bN27U008/re7du6ts2bK2dllZWerTp4/279+vlStXaty4cRo8eLCcnJxUsmRJ+fv7a86cOTp48KA2bNigYcOG5bu9t99+W0uXLtWPP/6oQYMG6cyZMzcd0IKDg/Xdd98pJSVFp06dUnZ2tm1e3759NXnyZBmGoQ4dOtzU+gHgegiAAO5aJUqU0Jo1a/T777/r3nvvVefOndWiRQvNmDHDrl2LFi0UHh6uJk2aqGvXrnr00Udt9xU6OTlp0aJF2r17t6pXr66hQ4fq1VdfzXd7kydP1uTJkxUdHa0tW7Zo+fLlKlWq1E3V3q9fP0VERKhevXoqXbq0tm7dapvXrVs3ubi4qFu3brJarTe1fgC4HothGIajiwAA/J/U1FSFhoZq165dqlOnjqPLAVAMEQABoIjIzs7W6dOnNWLECB05csSuVxAAbicuAQNAEbF161aVL19eu3bt0qxZsxxdDoBijB5AAAAAk6EHEAAAwGQIgAAAACZDAAQAADAZAiAAAIDJEAABAABMhgAIAABgMgRAAAAAkyEAAgAAmAwBEAAAwGT+H+ikSfdaznQ3AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
